{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the project in Optimization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from numpy.random import default_rng\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "w = np.array([1.,1.])\n",
    "b = 1.\n",
    "\n",
    "n = 1000\n",
    "n_A = np.random.randint(0,n)\n",
    "n_B = n-n_A\n",
    "margin = 5.e-1\n",
    "listA, listB = TestLinear(w,b,n_A,n_B,margin)\n",
    "\n",
    "x = np.concatenate((np.array(listA),np.array(listB)))\n",
    "\n",
    "y = np.concatenate((np.ones(n_A), -np.ones(n_B)))\n",
    "\n",
    "plt.scatter(x[:, 0], x[:, 1], c=y, cmap='coolwarm', edgecolors='k')\n",
    "plt.title(\"Data points\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alpha0 = np.zeros(n_A+n_B)\n",
    "tau = 1\n",
    "niter = 1000\n",
    "C = 3\n",
    "G = pairwise_kernels(x, metric = kernal_linear)  \n",
    "\n",
    "alpha = gradient_descent(alpha0, G, y, tau0=tau, niter=niter, C=C, tol=1e-7, projection=projection)\n",
    "\n",
    "w, b = w_b(alpha, y,x ,  C=C)\n",
    "plot_solution(x, y, w, b)\n",
    "\n",
    "\n",
    "C = 45\n",
    "G = pairwise_kernels(x, metric = kernal_linear)  \n",
    "\n",
    "alpha = gradient_descent(alpha0, G, y, tau0=tau, niter=niter, C=C, tol=1e-7, projection=projection)\n",
    "\n",
    "w, b = w_b(alpha, y,x ,  C=C)\n",
    "plot_solution(x, y, w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alpha0 = np.zeros(n_A+n_B)\n",
    "tau = 1\n",
    "niter = 1000\n",
    "C = 5\n",
    "G = pairwise_kernels(x, metric = kernal_linear)\n",
    "\n",
    "\n",
    "alpha = gradient_descent(alpha0, G, y, tau0=tau, niter=niter, C=C, tol=1e-7, projection=projection)\n",
    "alphagrad, fks = gradient_descent_linesearch(alpha0, G, y, tau0=tau, niter=niter, C=C, tol=1e-7, project=projection)\n",
    "\n",
    "w, b = w_b(alpha, y,x ,  C=C)\n",
    "plt.title(\"Gradient descent without linesearch\")\n",
    "plot_solution(x, y, w, b)\n",
    "\n",
    "w, b = w_b(alphagrad, y,x ,  C=C)\n",
    "plt.title(\"Gradient descent with linesearch\")\n",
    "plot_solution(x, y, w, b)\n",
    "\n",
    "\n",
    "plot_db(x, y, alpha, ker = kernal_linear, C=C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_db(x, y, alphagrad, ker = kernal_linear, C=C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the different kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "niter = 1000\n",
    "C = 5\n",
    "\n",
    "G = pairwise_kernels(x, metric = kernal_gaussian, sigma=1)\n",
    "alpha = gradient_descent(alpha0, G, y, tau, niter, C)\n",
    "# w, b = w_b(alpha, y, x, C=C)\n",
    "# plot_solution(x, y, w, b)\n",
    "plot_db(x, y, alpha, ker = kernal_gaussian, C=C)    \n",
    "\n",
    "G = pairwise_kernels(x, metric = kernal_inv_multiquadratic, sigma=1)\n",
    "alpha = gradient_descent(alpha0, G, y, tau, niter, C)\n",
    "# w, b = w_b(alpha, y, x, C=C)\n",
    "# plot_solution(x, y,  w, b)\n",
    "plot_db(x, y, alpha, ker = kernal_inv_multiquadratic, C=C)\n",
    "\n",
    "G = pairwise_kernels(x, metric = kernal_laplacian, sigma=1)\n",
    "alpha = gradient_descent(alpha0, G, y, tau, niter, C)\n",
    "# w, b = w_b(alpha, y, x, C=C)\n",
    "# plot_solution(x, y,  w, b)\n",
    "plot_db(x, y, alpha, ker = kernal_laplacian, C=C)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alpha0 = np.ones(n_A+n_B)\n",
    "tau = 1\n",
    "niter = 1000\n",
    "C = 3\n",
    "G = pairwise_kernels(x, metric = kernal_linear)\n",
    "\n",
    "\n",
    "alpha_test1, fks = gradient_descent_linesearch(alpha0, G, y, tau, niter=niter, C=0.8, L=10, tol=1e-5, project=projection)\n",
    "alpha_test2 = gradient_descent(alpha0, G, y, tau, niter=niter, C=0.8, tol=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha0 = np.ones(n_A+n_B)*0.5\n",
    "\n",
    "alpha_test1, fks = gradient_descent_linesearch(alpha0, G, y, tau, niter=1000, C=0.8, L=10, tol=1e-5)\n",
    "alpha_test2 = gradient_descent(alpha0, G, y, tau, niter=1000, C=0.8, tol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ker = kernal_linear\n",
    "ker = kernal_gaussian\n",
    "ker = kernal_inv_multiquadratic\n",
    "# ker = kernal_laplacian\n",
    "C = 1\n",
    "G = pairwise_kernels(x, metric = ker)  \n",
    "\n",
    "# np.random.seed(42)\n",
    "alpha, f = gradient_descent_linesearch(alpha0, G, y, tau0=tau, niter=niter, C=C, tol=1e-7, project=projection)\n",
    "\n",
    "plot_db(x, y, alpha, ker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with random initial contitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha0 = np.random.rand((n_A+n_B))\n",
    "ker = kernal_gaussian\n",
    "G = pairwise_kernels(x, metric = ker)  \n",
    "\n",
    "niter = 1000\n",
    "C = 5\n",
    "alpha_line, fk = gradient_descent_linesearch(alpha0, G, y, tau, niter, C = C, L=10, tol=1e-7)\n",
    "alpha_grad = gradient_descent(alpha0, G, y, tau, niter, C=C, tol=1e-7)\n",
    "\n",
    "plot_db(x, y, alpha_line, ker, C=C)\n",
    "plot_db(x, y, alpha_grad, ker, C=C)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using gradient descent on the iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data[:, :2][0:100]  # We'll use only the first two features for visualization\n",
    "Y = iris.target[0:100]  \n",
    "Y[Y == 0] = -1  # Convert to -1 and 1 for SVM\n",
    "Y[Y == 1] = 1\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y, cmap=plt.cm.Set1, s=50, edgecolors='k')\n",
    "plt.title('Iris Dataset (First Two Features)')\n",
    "plt.xlabel('Sepal Length (cm)')\n",
    "plt.ylabel('Sepal Width (cm)')\n",
    "plt.show()\n",
    "\n",
    "alpha0 = np.zeros(len(Y))\n",
    "ker = kernal_gaussian\n",
    "G = pairwise_kernels(X, metric=ker)\n",
    "C= 100\n",
    "\n",
    "alpha, f = gradient_descent_linesearch(alpha0, G, Y, tau0=tau, niter=niter, C=C, L=10, tol=1e-7, project=projection)\n",
    "\n",
    "plot_db(X, Y, alpha, ker=ker, C=C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection_AL(vector, proj_par):\n",
    "    lower_bounds = proj_par[0]\n",
    "    upper_bounds = proj_par[1]\n",
    "    dimension = len(vector)\n",
    "    proj_vector = np.array([])\n",
    "    for k in range(0, dimension):\n",
    "        if vector[k]<lower_bounds[k]:\n",
    "            proj_vector = np.append(proj_vector, np.array([lower_bounds[k]]))\n",
    "        elif vector[k] > upper_bounds[k]:\n",
    "            proj_vector = np.append(proj_vector, np.array([upper_bounds[k]]))\n",
    "        else:\n",
    "            proj_vector = np.append(proj_vector, np.array([vector[k]]))\n",
    "    return proj_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BCLM(vec_0, lambd_0, mu_0, tol_1, tol_2, maxiter, func, func_par, constr, constr_par, grad, grad_par, project, project_par, linesearch, linesearch_par): #Algoritme 17.4 i boka\n",
    "    \n",
    "    tol_1_k = 1/mu_0\n",
    "    tol_2_k = 1/mu_0**(0.1)\n",
    "\n",
    "    vec_k = vec_0\n",
    "    lambd_k = lambd_0\n",
    "    mu_k = mu_0\n",
    "\n",
    "    grad_par[0] = lambd_k\n",
    "    grad_par[1] = mu_k\n",
    "    func_par[0] = lambd_k\n",
    "    func_par[1] = mu_k\n",
    "\n",
    "    for _ in range(0, maxiter):\n",
    "\n",
<<<<<<< HEAD
    "        wbxis_k = 0 #solution to projected gradient descent with tolerance tol_1_k\n",
    "        distance_k = 0 #wbxis_k - projection\n",
=======
    "        tau_0 = 1\n",
    "        projected_gradient_method = general_projected_gradient_linesearch(vec_k, tau_0, func, func_par, grad, grad_par, project, project_par, linesearch, linesearch_par, tol = tol_1_k, L = 10)[0]\n",
>>>>>>> 5504059 (Forsøk på å implementera AL)
    "\n",
    "        #general_projected_gradient_linesearch(vec_0, tau_0, func, func_par, grad, grad_par, project, project_par, linesearch, linesearch_par, tol, L = 10)\n",
    "\n",
    "        vec_k = projected_gradient_method[0]\n",
    "        d_k = projected_gradient_method[2]\n",
    "\n",
    "        c_k = constr(vec_k, constr_par)\n",
    "        c_k_norm = np.linalg.norm(c_k)\n",
    "\n",
    "        if c_k_norm <= tol_2_k:\n",
    "            \n",
    "            if c_k_norm <= tol_2 and d_k <= tol_1:\n",
    "                return vec_k, lambd_k\n",
    "            \n",
    "            lambd_k = lambd_k - mu_k*c_k\n",
    "            tol_1_k = tol_1_k/mu_k\n",
    "            tol_2_k = tol_2_k/mu_k**(0.9)\n",
    "\n",
    "            grad_par[0] = lambd_k\n",
    "            func_par[0] = lambd_k\n",
    "        \n",
    "        else:\n",
    "            mu_k = 100*mu_k\n",
    "            tol_1_k = tol_1_k/mu_k\n",
    "            tol_2_k = tol_2_k/mu_k**(0.1)\n",
    "\n",
    "            grad_par[1] = mu_k\n",
    "            func_par[1] = mu_k\n",
    "    \n",
    "    return \"Ingen konvergens\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AL(vec, AL_par): #kontroller at dette er rett\n",
    "\n",
    "    lambd = AL_par[0]\n",
    "    mu = AL_par[1]\n",
    "\n",
    "    d = AL_par[2]\n",
    "    M = AL_par[3]\n",
    "\n",
    "    x = AL_par[4]\n",
    "    y = AL_par[5]\n",
    "\n",
    "    C = AL_par[6]\n",
    "\n",
    "    w = vec[0:d]\n",
    "    b = vec[d]\n",
    "    xi = vec[d+1:d+1+M]\n",
    "    s = vec[d+1+M:]\n",
    "    \n",
    "    AL = 0.5*np.linalg.norm(w)**2\n",
    "    for i in range(0, len(xi)):\n",
    "        indreprod = np.inner(w, x[i])\n",
    "        AL = AL + C*xi[i] - lambd[i]*(y[i]*(indreprod + b) + xi[i] - s[i] - 1) + 0.5*mu*(y[i]*(indreprod + b) + xi[i] - s[i] - 1)**2\n",
    "    return AL\n",
    "\n",
    "#print(AL(np.array([1,1]),1, np.array([1,1]),np.array([1,1]), np.array([1,1]), 2, np.array([np.array([1,1]), np.array([1,1])]), np.array([1,1]), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_AL(vec, gradAL_par): #Kontroller at dette er rett\n",
    "    \n",
    "    lambd = gradAL_par[0]\n",
    "    mu = gradAL_par[1]\n",
    "\n",
    "    d = gradAL_par[2]\n",
    "    M = gradAL_par[3]\n",
    "\n",
    "    x = gradAL_par[4]\n",
    "    y = gradAL_par[5]\n",
    "\n",
    "    C = gradAL_par[6]\n",
    "\n",
    "    w = vec[0:d]\n",
    "    b = vec[d]\n",
    "    xi = vec[d+1:d+1+M]\n",
    "    s = vec[d+1+M:]\n",
    "    \n",
    "    grad_AL = np.array([])\n",
    "    \n",
    "    #Elements from w\n",
    "    for k in range(0, d):\n",
    "        grad_k = w[k]\n",
    "        for i in range(0, M):\n",
    "            indresum = 0\n",
    "            for l in range(0, d):\n",
    "                indresum = indresum + 2*x[i][k]*x[i][l]*w[l]\n",
    "            grad_k = grad_k - lambd[i]*y[i]*x[i][k] + 0.5*mu*(y[i]**2 * indresum + 2*y[i]**2 * b * x[i][k] + 2*y[i]*xi[i]*x[i][k] - 2*y[i]*s[i]*x[i][k] -2*y[i]*x[i][k])\n",
    "        grad_AL = np.append(grad_AL, np.array([grad_k]))\n",
    "    \n",
    "    #Elements from b\n",
    "    grad_b = 0\n",
    "    for i in range(0, M):\n",
    "        grad_b = grad_b - lambd[i]*y[i] + 0.5*mu*(2*y[i]**2*b + 2*y[i]**2*np.inner(w, x[i]) + 2*y[i]*xi[i] - 2*y[i]*s[i] - 2*y[i])\n",
    "    grad_AL = np.append(grad_AL, np.array([grad_b]))\n",
    "\n",
    "    #Elements from xi\n",
    "    for i in range(0, M):\n",
    "        grad_xi = C - lambd[i] + 0.5*mu*(2*xi[i] + 2*y[i]*np.inner(w, x[i]) + 2*y[i]*b - 2*s[i] - 2)\n",
    "        grad_AL = np.append(grad_AL, np.array([grad_xi]))\n",
    "\n",
    "    #Elements from s\n",
    "    for i in range(0, M):\n",
    "        grad_s = -lambd[i] + 0.5*mu*(2*s[i] - 2*y[i]*np.inner(w, x[i]) - 2*y[i]*b - 2*xi[i] + 2)\n",
    "        grad_AL = np.append(grad_AL, np.array([grad_s]))\n",
    "    \n",
    "    return grad_AL\n",
    "\n",
    "#print(grad_AL(np.array([1,1]),1, np.array([1,1]),np.array([1,1]), np.array([1,1]), 2, np.array([np.array([1,1]), np.array([1,1])]), np.array([1,1]), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "def analytic_linesearch(d_k, A, alpha):\n",
    "    dot1 = np.dot(d_k, np.dot(A, d_k))\n",
    "    dot2 = np.dot(d_k, np.dot(A, alpha))\n",
    "    dot3 = np.dot(alpha, np.dot(A, d_k))\n",
    "    dot4 = np.sum(d_k)\n",
    "    theta = - (0.5*dot2 + 0.5 *dot3 - dot4)/dot1\n",
    "    return theta\n",
    "\n",
    "def linesearch():\n",
    "    pass\n"
=======
    "def general_projected_gradient_linesearch(vec_0, tau_0, func, func_par, grad, grad_par, project, project_par, linesearch, linesearch_par, tol, L = 10):\n",
    "\n",
    "    vec = vec_0\n",
    "    tau = tau_0\n",
    "    \n",
    "    f_ref = np.inf\n",
    "    f_best = func(vec, func_par)\n",
    "    f_c = f_best\n",
    "    ell = 0\n",
    "    f_ks = np.zeros(niter)\n",
    "\n",
    "    for i in range(niter):\n",
    "\n",
    "        d_k = project(vec - tau*grad(vec, grad_par), project_par) - vec\n",
    "\n",
    "        if np.max(np.abs(d_k)) < tol:\n",
    "            print(\"Converged after\", i, \"iterations\")\n",
    "            return vec, f_ks, d_k\n",
    "        \n",
    "        if i%500 == 0:\n",
    "            print(\"Iteration\", i, \":\", np.max(np.abs(d_k))) \n",
    "        \n",
    "        f_k = func(vec, func_par)\n",
    "        f_ks[i] = f_k\n",
    "        if f_k < f_best:\n",
    "            f_best = f_k\n",
    "            f_c = f_k\n",
    "            ell = 0\n",
    "        else:\n",
    "            f_c = np.max([f_c, f_k])\n",
    "            ell = ell + 1\n",
    "        if ell == L:\n",
    "            f_ref = f_c\n",
    "            f_c = f_k\n",
    "            ell = 0\n",
    "\n",
    "        if func(vec + d_k, func_par) > f_ref:\n",
    "            theta = linesearch(vec, d_k, linesearch_par)\n",
    "            \n",
    "        else:\n",
    "            theta = 1\n",
    "\n",
    "        vec = vec + theta * d_k\n",
    "        \n",
    "        tau = general_BB_steplength(vec-theta*d_k, vec, grad, grad_par, taumax=1e5, taumin=1e-5)\n",
    "\n",
    "\n",
    "    print(\"Did not converge after\", niter, \"iterations\")\n",
    "    \n",
    "    return vec, f_ks, d_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_BB_steplength(vec_k, vec_k1, grad, grad_par, taumax=1e5, taumin=1e-5):\n",
    "    nevner = np.dot((vec_k1 - vec_k), (grad(vec_k1, grad_par) - grad(vec_k, grad_par)))\n",
    "    if  nevner<= 0:\n",
    "        return taumax\n",
    "    tau = np.dot((vec_k1 - vec_k), (vec_k1 - vec_k)) / nevner\n",
    "    return max(min(tau, taumax), taumin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linesearch_AL(vec, d_k, linesearch_par):\n",
    "    \n",
    "    lambd = linesearch_par[0]\n",
    "    mu = linesearch_par[1]\n",
    "\n",
    "    d = linesearch_par[2]\n",
    "    M = linesearch_par[3]\n",
    "\n",
    "    x = linesearch_par[4]\n",
    "    y = linesearch_par[5]\n",
    "\n",
    "    C = linesearch_par[6]\n",
    "\n",
    "    w = vec[0:d]\n",
    "    b = vec[d]\n",
    "    xi = vec[d+1:d+1+M]\n",
    "    s = vec[d+1+M:]\n",
    "\n",
    "    d_w = d_k[0:d]\n",
    "    d_b = d_k[d]\n",
    "    d_xi = d_k[d+1:d+1+M]\n",
    "    d_s = d_k[d+1+M:]\n",
    "    \n",
    "    A = np.sum(d_k[0:d])\n",
    "    B = np.inner(w, d_w) + C*np.sum(d_xi)\n",
    "\n",
    "    for i in range(0, M):\n",
    "        indprod_1 = np.inner(d_w, x[i])\n",
    "        indprod_2 = np.inner(w, x[i])\n",
    "        \n",
    "        A = A + mu* (indprod_1**2 + d_k[d]**2 + d_k[d+i]**2 + d_k[d+M+i]**2 + 2*d_k[d]*indprod_1 + 2*y[i]*d_k[d+i]*indprod_1 - 2*y[i]*d_k[d+M+i]*indprod_1 + 2*y[i]*d_k[d]*d_k[d+i] - 2*y[i]*d_k[d]*d_k[d+M+i] - 2*d_k[d+i]*d_k[d+M+i])\n",
    "\n",
    "        B = B + lambd[i]* (y[i]*(indprod_1 + d_k[d]) + d_k[d+i] - d_k[d+M+i]) + mu*(indprod_2 * indprod_1 + b*d_k[d] + xi[i]*d_k[d+i] + s[i]*d_k[d+M+i] + b*indprod_1 + d_k[d]*indprod_2 + y[i]*xi[i]*indprod_1 + y[i]*d_k[d+i]*indprod_2 - y[i]*s[i]*indprod_1 - y[i]*d_k[d+M+i]*indprod_2 - y[i]*indprod_1 + y[i]*d_k[d]*xi[i] + y[i]*d_k[d+i]*b - y[i]*d_k[d+M+i]*b - y[i]*d_k[d]*s[i] - y[i]*d_k[d] - d_k[d+i]*s[i] - d_k[d+M+i]*xi[i])\n",
    "    \n",
    "    theta = -B/A\n",
    "\n",
    "    return theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = len(x[0])\n",
    "M = len(x)\n",
    "\n",
    "C = 5\n",
    "\n",
    "startpunkt = np.ones(d+1+2*M)\n",
    "lambd_0 = np.ones(M)\n",
    "mu_0 = 10\n",
    "tol_1 = 1e-7\n",
    "tol_2 = 1e-7\n",
    "maxiter = 1000\n",
    "\n",
    "AL_par = [lambd_0, mu_0, d, M, x, y, C]\n",
    "gradAL_par = [lambd_0, mu_0, d, M, x, y, C]\n",
    "constr_par = [x, y]\n",
    "\n",
    "lower_bound = np.append([- np.inf]*(d+1), [0]*2*M)\n",
    "upper_bound = [np.inf]*(d+1+2*M)\n",
    "project_par = [lower_bound, upper_bound]\n",
    "\n",
    "linesearch_par = [lambd_0, mu_0, d, M, x, y, C]\n",
    "\n",
    "BCLM(startpunkt, lambd_0, mu_0, tol_1, tol_2, maxiter, AL, AL_par, constraints, constr_par, grad_AL, gradAL_par, projection_AL, project_par, linesearch_AL, linesearch_par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constraints(vec, constr_par):\n",
    "\n",
    "    d = 2 #len(x[0])\n",
    "    M = len(x)\n",
    "\n",
    "    print(\"vec\", vec)\n",
    "\n",
    "    w = vec[0:d]\n",
    "    b = vec[d]\n",
    "    xi = vec[d+1:d+M+1]\n",
    "    s = vec[d+M+1:]\n",
    "\n",
    "    c_vec = np.array([])\n",
    "    for i in range(0, len(x)):\n",
    "        c_vec = np.append(c_vec, np.array([y[i]*(np.inner(w, x[i]) + b) + xi[i] -s[i]-1]))\n",
    "    \n",
    "    return c_vec"
>>>>>>> 5504059 (Forsøk på å implementera AL)
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
