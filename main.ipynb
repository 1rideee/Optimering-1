{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the project in Optimization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from numpy.random import default_rng\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "w = np.array([1.,1.])\n",
    "b = 1.\n",
    "\n",
    "n = 100\n",
    "n_A = np.random.randint(0,n)\n",
    "n_B = n-n_A\n",
    "margin = 5.e-1\n",
    "listA,listB = TestLinear(w,b,n_A,n_B,margin)\n",
    "[plt.scatter(x[0],x[1],color=\"r\") for x in listA]\n",
    "[plt.scatter(x[0],x[1],color=\"b\") for x in listB]\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate((np.array(listA),np.array(listB)))\n",
    "\n",
    "y = np.concatenate((np.ones(n_A), -np.ones(n_B)))\n",
    "\n",
    "\n",
    "G = pairwise_kernels(x, metric = kernal_linear)\n",
    "\n",
    "\n",
    "print(np.shape(G))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projected gradient descent algorithm\n",
    "\n",
    "\\begin{align*}\n",
    "    \\alpha^{(k+1)} &= \\alpha^{(k)}+ d^{(k)}\\\\\n",
    "    \\text{where}&\\\\\n",
    "    d^{(k)} & = \\pi _{\\Omega} \\left(\\alpha^{(k)}-\\tau_k \\nabla f(\\alpha^{(k)}) \\right) - \\alpha^{(k)}\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "    f(\\alpha) &:= \\frac{1}{2} \\langle\\alpha, YGY\\alpha\\rangle- \\langle1_M,\\alpha\\rangle\\\\\n",
    "    \\Omega &= \\{\\alpha \\in \\mathbb{R}^M : \\langle y, \\alpha \\rangle=0 \\quad \\text{and} \\quad 0\\leq \\alpha \\leq C \\}\n",
    "\\end{align*}\n",
    "\n",
    "is a feasible set, $\\pi_{\\Omega}$ denotes the projection onto $\\Omega$ and $\\tau_k >0$ is a suitible steplength.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alpha0 = np.ones(n_A+n_B)\n",
    "tau = 0.01\n",
    "niter = 1000\n",
    "C = 0.8\n",
    "# alpha = gradient_descent(alpha0, G, y, tau, niter, C=0.8, tol=1e-1)\n",
    "# print(alpha)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(alpha0, G, y , tau0, niter, C=100, tol = 1e-7):\n",
    "    '''\n",
    "    Perform the gradient descent algorithm with a projected gradient step.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    alpha0 : numpy array\n",
    "        Initial guess for the alpha vector.\n",
    "    G : numpy array\n",
    "        The Gram matrix.\n",
    "    y : numpy array\n",
    "        The target vector.\n",
    "    tau0 : float\n",
    "        Initial step length.\n",
    "    niter : int\n",
    "        Number of iterations.\n",
    "    C : float, optional\n",
    "        The penalty parameter. The default is 100.\n",
    "    tol : float, optional\n",
    "        Tolerance for the convergence. The default is 1e-7.\n",
    "\n",
    "    '''\n",
    "\n",
    "    alpha = alpha0\n",
    "    Y = np.diag(y)\n",
    "    #Saves the A matrix to save on computation time\n",
    "    A = np.dot(Y,np.dot(G,Y))\n",
    "    tau = tau0\n",
    "\n",
    "    for i in range(niter):\n",
    "        \n",
    "        d_k = projection(alpha - tau * gradientf(alpha, A), y=y, Y=Y, C=C) - alpha\n",
    "        \n",
    "        # Check for convergence when the largest component of the gradient is smaller than the tolerance\n",
    "        if np.max(np.abs(d_k)) < tol:\n",
    "            print(\"Converged after\", i, \"iterations\")\n",
    "            return alpha\n",
    "        \n",
    "        if i%500 == 0:\n",
    "            print(\"Iteration\", i, \":\", np.max(np.abs(d_k))) \n",
    "        \n",
    "        alpha = alpha + d_k \n",
    "\n",
    "        #Creates the Barzilai-Borwein step length\n",
    "        tau = BB_step_length((alpha-d_k), alpha, gradientf, A, taumax=1e5, taumin=1e-5)\n",
    "    \n",
    "    print(\"Did not converge after\", niter, \"iterations\", np.max(np.abs(d_k)))\n",
    "    return alpha\n",
    "\n",
    "def projection(alpha, y, Y, C=1.0, tol=1e-6, max_iter=100, delta=1e-1):  \n",
    "    \"\"\"\n",
    "    Project the vector alpha onto the feasible region defined by the constraints.\n",
    "    Parameters\n",
    "    ----------\n",
    "    alpha : numpy array\n",
    "        The vector to be projected.\n",
    "    y : numpy array\n",
    "        The target vector.\n",
    "    Y : numpy array\n",
    "        The diagonal matrix of the target vector.\n",
    "    C : float, optional\n",
    "        The penalty parameter. The default is 1.\n",
    "    tol : float, optional\n",
    "        The tolerance for the convergence. The default is 1e-6.\n",
    "    max_iter : int, optional\n",
    "        The maximum number of iterations. The default is 100.\n",
    "    delta : float, optional\n",
    "        The step size for the binary search. The default is 1e-3.\n",
    "    Returns\n",
    "    -------\n",
    "    projected_alpha : numpy array\n",
    "        The projected vector.\n",
    "    \"\"\"\n",
    "\n",
    "    beta = alpha.copy()\n",
    "    low, high = -10, 10\n",
    "    \n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        \n",
    "        # Check if the current alpha is within the feasible region\n",
    "        inner_low = np.dot(y, alpha_Lagrange(beta, low, Y, C))\n",
    "        \n",
    "        if inner_low  > 0:\n",
    "            cond= True\n",
    "            while cond:\n",
    "                high = low \n",
    "                low = low - delta\n",
    "                cond = np.dot(y, alpha_Lagrange(beta, low, Y, C)) < 0 and np.dot(y, alpha_Lagrange(beta, high, Y, C))>0\n",
    "\n",
    "        inner_high = np.dot(y, alpha_Lagrange(beta, high, Y, C))\n",
    "        if inner_high < 0:\n",
    "            cond= True\n",
    "            while cond:\n",
    "                low = high\n",
    "                high = high + delta\n",
    "                cond = np.dot(y, alpha_Lagrange(beta, low, Y, C)) < 0 and np.dot(y, alpha_Lagrange(beta, high, Y, C))>0\n",
    "\n",
    "        # Perform binary search to find the Lagrange multiplier\n",
    "        # lambda_mid = (low + high) / 2.0\n",
    "\n",
    "        lambda_mid = high - (high-low)* np.dot(y, alpha_Lagrange(beta, high, Y, C))/(np.dot(y, alpha_Lagrange(beta, high, Y, C))-np.dot(y, alpha_Lagrange(beta, low, Y, C)))\n",
    "        # print(\"lambda_mid\", lambda_mid)\n",
    "        \n",
    "        projected_alpha = alpha_Lagrange(beta, lambda_mid, Y, C)\n",
    "    \n",
    "        constraint_value = np.dot(y, projected_alpha)\n",
    "        \n",
    "        # Check if the constraint is satisfied\n",
    "        if abs(constraint_value) < tol:\n",
    "            return projected_alpha  \n",
    "    \n",
    "        if constraint_value > 0:\n",
    "            high = lambda_mid\n",
    "        else:\n",
    "            low = lambda_mid\n",
    "    print(\"Warning: Maximum iterations reached without convergence. lambda:\", lambda_mid )\n",
    "    return projected_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = gradient_descent(alpha0, G, y, tau, niter=1000, C=0.6, tol=1e-7)\n",
    "# print(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha1 = gradient_descent(alpha0, G, y, tau, niter=100, C=100, tol=1e-7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(range(len(alpha)), alpha1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_b(alpha, y, x, C=0.8):\n",
    "    \n",
    "    # I_s = np.where(alpha > 0 and alpha < C)\n",
    "    I_s = [i for i in range(len(alpha)) if alpha[i] > 0 and alpha[i] < C]\n",
    "    \n",
    "    w = np.sum(alpha[I_s]*y[I_s]*x[I_s].T, axis=1) \n",
    "    b = y[I_s[0]] - np.dot(w, x[I_s[0]])\n",
    "    return w, b\n",
    "    \n",
    "\n",
    "\n",
    "def plot_solution(x, y, alpha, w, b):\n",
    "\n",
    "    plt.scatter(x[:,0], x[:,1], c=y)\n",
    "    plt.plot([-3, 3], [(-b - w[0] * (-3)) / w[1], (-b - w[0] * 3) / w[1]], 'k-')\n",
    "    #excact solution\n",
    "    plt.plot([-3, 3], [(-1 - 1 * (-3)), (-1 - 1 * 3) ], 'r--')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "w, b = w_b(alpha, y, x, C = 0.6)\n",
    "\n",
    "plot_solution(x, y, alpha, w, b)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, b = w_b(alpha1, y, x, C=100)\n",
    "\n",
    "plot_solution(x, y, alpha1, w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "niter = 500\n",
    "C=0.006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "G = pairwise_kernels(x, metric = kernal_gaussian, sigma=1)\n",
    "alpha = gradient_descent(alpha0, G, y, tau, niter, C)\n",
    "w, b = w_b(alpha, y, x)\n",
    "plot_solution(x, y, alpha, w, b)\n",
    "\n",
    "G = pairwise_kernels(x, metric = kernal_inv_multiquadratic, sigma=1)\n",
    "alpha = gradient_descent(alpha0, G, y, tau, niter, C)\n",
    "\n",
    "w, b = w_b(alpha, y, x)\n",
    "plot_solution(x, y, alpha, w, b)\n",
    "\n",
    "\n",
    "G = pairwise_kernels(x, metric = kernal_laplacian, sigma=1)\n",
    "alpha = gradient_descent(alpha0, G, y, tau, niter, C)\n",
    "\n",
    "w, b = w_b(alpha, y, x)\n",
    "plot_solution(x, y, alpha, w, b)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = pairwise_kernels(x, metric = kernal_gaussian, sigma=0.5)\n",
    "alpha = gradient_descent(alpha0, G, y, tau, niter = 100, C=0.02)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, b = w_b(alpha, y, x, C=0.02)\n",
    "\n",
    "plot_solution(x, y, alpha, w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, b = w_b(alpha, y, x, C=0.8)\n",
    "\n",
    "plot_solution(x, y, alpha, w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_linesearch(alpha0, G, y , tau0, niter, C=100, L = 10, tol = 1e-10):\n",
    "    \"\"\"\"\n",
    "    Gradient descent with backtracking line search\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    alpha0 : np.array\n",
    "        Initial point\n",
    "    G : np.array\n",
    "        Kernel matrix\n",
    "    y : np.array\n",
    "        Labels\n",
    "    tau0 : float\n",
    "        Initial step size\n",
    "    niter : int\n",
    "        Number of iterations\n",
    "    C : float\n",
    "        Regularization parameter\n",
    "    L : int\n",
    "        Number of iterations before reference function is updated\n",
    "\n",
    "    tol : float\n",
    "        Tolerance for convergence\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    alpha : np.array\n",
    "        Optimal alpha\n",
    "    \"\"\"\n",
    "    alpha = alpha0\n",
    "    Y = np.diag(y)\n",
    "    A = np.dot(Y,np.dot(G,Y))\n",
    "    tau = tau0\n",
    "\n",
    "    f_ref = np.inf\n",
    "    f_best = f(alpha, A)\n",
    "    f_c = f_best\n",
    "    ell = 0\n",
    "    f_ks = np.zeros(niter)\n",
    "    for i in range(niter):\n",
    "\n",
    "\n",
    "        d_k = projection(alpha - tau*gradientf(alpha, A), y=y, Y=Y, C=C) - alpha\n",
    "\n",
    "        if np.max(np.abs(d_k)) < tol:\n",
    "            print(\"Converged after\", i, \"iterations\")\n",
    "            return alpha, f_ks\n",
    "        \n",
    "        if i%500 == 0:\n",
    "            print(\"Iteration\", i, \":\", np.max(np.abs(d_k))) \n",
    "        \n",
    "        f_k = f(alpha, A)\n",
    "        f_ks[i] = f_k\n",
    "        if f_k < f_best:\n",
    "            f_best = f_k\n",
    "            f_c = f_k\n",
    "            ell = 0\n",
    "        else:\n",
    "            f_c = np.max([f_c, f_k])\n",
    "            ell = ell + 1\n",
    "        if ell == L:\n",
    "            f_ref = f_c\n",
    "            f_c = f_k\n",
    "            ell = 0\n",
    "\n",
    "        \n",
    "\n",
    "        if f(alpha + d_k, A) > f_ref:\n",
    "            dot1 = np.dot(d_k, np.dot(A, d_k))\n",
    "            dot2 = np.dot(d_k, np.dot(A, alpha))\n",
    "            dot3 = np.dot(alpha, np.dot(A, d_k))\n",
    "            dot4 = np.sum(d_k)\n",
    "            theta = - (0.5*dot2 + 0.5 *dot3 - dot4)/dot1\n",
    "            # print(\"theta\", theta, np.shape(alpha), np.shape(d_k))\n",
    "            \n",
    "        else:\n",
    "            theta = 1\n",
    "\n",
    "        alpha = alpha + theta * d_k\n",
    "        \n",
    "        tau = BB_step_length(alpha-theta*d_k, alpha, gradientf, A, taumax=1e5, taumin=1e-5)\n",
    "\n",
    "\n",
    "    print(\"Did not converge after\", niter, \"iterations\")\n",
    "    \n",
    "    return alpha, f_ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha0 = np.ones(n_A+n_B)*0.5\n",
    "\n",
    "alpha_test1, fks = gradient_descent_linesearch(alpha0, G, y, tau, niter=5000, C=0.8, L=10, tol=1e-5)\n",
    "alpha_test2 = gradient_descent(alpha0, G, y, tau, niter=5000, C=0.8, tol=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(range(len(fks[1:-1])), fks[1:-1])\n",
    "plt.show()\n",
    "plt.scatter(range(len(alpha0)),alpha0)\n",
    "plt.scatter( range(len(alpha_test1)),alpha_test1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "alpha0 = np.random.rand((n_A+n_B))\n",
    "print(\"alpha0\", alpha0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha0 = np.random.rand((n_A+n_B))\n",
    "\n",
    "niter = 3000\n",
    "alpha_line = gradient_descent_linesearch(alpha0, G, y, tau, niter, C = 0.006, L=10, tol=1e-7)\n",
    "alpha_grad = gradient_descent(alpha0, G, y, tau, niter, C=0.006, tol=1e-7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha0 = np.ones(n_A+n_B)\n",
    "niter = 3000\n",
    "\n",
    "alpha_line1 = gradient_descent_linesearch(alpha0, G, y, tau, niter, C = 0.6, L=10, tol=1e-7)\n",
    "alpha_grad1 = gradient_descent(alpha0, G, y, tau, niter, C=0.6, tol=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha0 = np.ones(n_A+n_B)* 0.5\n",
    "niter = 5000\n",
    "\n",
    "alpha_line2 = gradient_descent_linesearch(alpha0, G, y, tau, niter, C = 0.6, L=10, tol=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(range(len(alpha0)), alpha0)\n",
    "plt.scatter(range(len(alpha_line[0])), alpha_line[0], label=\"line search\")\n",
    "# plt.scatter(range(len(alpha_test1)),alpha_test1, label=\"line search test\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# print(alpha_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "w, b= w_b(alpha_grad, y, x)\n",
    "print(w,b)\n",
    "plot_solution(x, y, alpha_grad, w, b)\n",
    "\n",
    "w, b= w_b(alpha_line[0], y, x)\n",
    "print(w,b)\n",
    "plot_solution(x, y, alpha_line[0], w, b)\n",
    "\n",
    "\n",
    "w, b = w_b(alpha_line1[0], y, x)\n",
    "print(w,b)\n",
    "plot_solution(x, y, alpha_line1[0], w, b)\n",
    "\n",
    "\n",
    "\n",
    "w, b= w_b(alpha_line2[0], y, x)\n",
    "print(w,b)\n",
    "\n",
    "plot_solution(x, y, alpha_line2[0], w, b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(range(len(fks[1:-1])), fks[1:-1], label=\"line search test\")\n",
    "plt.scatter(range(len(alpha_line[1])), alpha_line[1], label=\"line search\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def w_SVM(alpha, x, y, point_x , kernel = kernal_gaussian):\n",
    "\n",
    "    I_s = [i for i in range(len(alpha)) if alpha[i] > 0 ]\n",
    "    # print(\"kernel: \", kernel(x[I_s[0]], point_x))\n",
    "    # print(\"alpha: \", len(alpha[I_s]))\n",
    "    # print(\"y: \", y[I_s])\n",
    "    # print(\"kernel\", x[I_s])\n",
    "    # print(\"kernel: \", np.max(kernel(x[I_s], point_x)), np.min(kernel(x[I_s], point_x)))\n",
    "    w = np.sum(alpha[I_s] * y[I_s] * kernel(x[I_s], point_x)) \n",
    "    return w\n",
    "\n",
    "def b_SVM(alpha, x, y, point_x , kernel = kernal_gaussian, C=0.6):\n",
    "\n",
    "    I_s = [i for i in range(len(alpha)) if alpha[i] > 0 and alpha[i] < C]\n",
    "    \n",
    "    b = y[I_s[0]]- np.sum(alpha[I_s]*y[I_s]*kernel(x[I_s], x[I_s[0]]))\n",
    "    return b\n",
    "\n",
    "points = np.linspace(-3, 3, 100)\n",
    "# print(alpha)\n",
    "w = [w_SVM(alpha, x, y, p) for p in points]\n",
    "b = b_SVM(alpha, x, y, points[0])\n",
    "\n",
    "plt.scatter(points, w+b, label=\"w_SVM\")\n",
    "plt.scatter(x[:,0], x[:,1], c=y)\n",
    "plt.show()\n",
    "# print(\"w, b\", w, b)\n",
    "\n",
    "# plt.plot(alpha_line1[0], label=\"line search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_function(alpha, x, y, point_x, kernel=kernal_gaussian):\n",
    "    I_s = [i for i in range(len(alpha)) if alpha[i] > 1e-5]  # threshold to avoid tiny alphas\n",
    "    return np.sum(alpha[I_s] * y[I_s] * kernel(x[I_s], point_x))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
